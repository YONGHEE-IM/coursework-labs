## 문제 1

def calculate_error(true_list, compare_list):
    # 1. 두 리스트의 각 요소 차이를 구함
    differences = [t - c for t, c in zip(true_list, compare_list)]

    # 2. 차이를 제곱
    squared_differences = [d ** 2 for d in differences]

    # 3. 제곱값의 평균 계산
    mean_squared_error = sum(squared_differences) / len(squared_differences)

    # 4. 소수점 둘째 자리 반올림
    rounded_result = round(mean_squared_error, 2)

    return rounded_result

# 테스트 예시
정답_list = [1, 2, 3, 4, 5]
비교_list = [1, 2, 4, 3, 5]
result = calculate_error(정답_list, 비교_list)
print(result)

## 문제 2
from keras.models import Sequential
from keras.layers import Conv2D, Flatten, Dense

# 모델 생성
model = Sequential()

# 첫 번째 Convolution 레이어
model.add(Conv2D(32, kernel_size(3, 3), activation='relu', input_shape=(64, 64, 3)))

# 두 번째 Convolution 레이어
model.add(Conv2D(64, kernel_size(3, 3), activation='relu'))

# 세 번쨰 Convolution 레이어
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))

# Flatten 레이어
model.add(Flatten())

# 첫 번째 Dense 레이어
model.add(Dense(256, activation='relu'))

# 두 번째 Dense 레이어 (출력층)
model.add(Dense(10, activation='softmax'))

# 모델 요약 출력
model.summary()

## 문제 3
import numpy as np
from keras.models import Sequential
from keras.layers import Conv2D, Flatten, Dense
from keras.optimizers import Adam
from keras.losses import SparseCategoricalCrossentropy
from keras.metrics import CategoricalAccuracy
from keras.datasets import mnist
from keras.utils import to_categorical
from keras.preprocessing.image import load_img, img_to_array

# 1. 데이터셋 로드 및 전처리
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# 데이터 크기 조정 및 정규화
train_images = train_images.reshape(-1, 28, 28, 1) / 255.0
test_images = test_images.reshape(-1, 28, 28, 1) / 255.0

# 학습 및 테스트 데이터 개수 설정
train_cnt = 1000  # 사용할 학습 데이터 개수
test_cnt = 200    # 사용할 테스트 데이터 개수
train_images, train_labels = train_images[:train_cnt], train_labels[:train_cnt]
test_images, test_labels = test_images[:test_cnt], test_labels[:test_cnt]

# 2. 모델 정의
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    Conv2D(128, kernel_size=(3, 3), activation='relu'),
    Flatten(),
    Dense(256, activation='relu'),
    Dense(10, activation='softmax')
])

# 3. 모델 컴파일
model.compile(
    optimizer=Adam(),
    loss=SparseCategoricalCrossentropy(),
    metrics=[CategoricalAccuracy()]
)

# 4. 모델 학습
model.fit(train_images, train_labels, epochs=1, batch_size=32)

# 5. 모델 평가
loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)
print(f"테스트 데이터셋에서의 손실값: {loss:.4f}")
print(f"테스트 데이터셋에서의 정확도: {accuracy:.4f}")

# 6. 특정 이미지 예측
# 이미지 로드 및 전처리
input_image = load_img('7.png', color_mode='grayscale', target_size=(28, 28))  # 이미지 불러오기
input_array = img_to_array(input_image).reshape(1, 28, 28, 1) / 255.0  # 크기 조정 및 정규화

# 예측
predicted_label = np.argmax(model.predict(input_array), axis=-1)
print(f"예측된 클래스: {predicted_label[0]}")


## 문제 4
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Input

# LeNet 구현
model = Sequential([
    # Input Layer
    Input(shape=(32, 32, 1)),  # 32x32 크기의 흑백 이미지 입력

    # 첫 번째 Convolutional Layer
    Conv2D(filters=6, kernel_size=(5, 5), strides=1, activation='tanh', padding='valid'),
    
    # 첫 번째 Average Pooling Layer
    AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'),

    # 두 번째 Convolutional Layer
    Conv2D(filters=16, kernel_size=(5, 5), strides=1, activation='tanh', padding='valid'),
    
    # 두 번째 Average Pooling Layer
    AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'),

    # 세 번째 Convolutional Layer
    Conv2D(filters=120, kernel_size=(5, 5), strides=1, activation='tanh', padding='valid'),
    
    # Flatten Layer
    Flatten(),
    
    # 첫 번째 Fully Connected Layer
    Dense(units=84, activation='tanh'),
    
    # 두 번째 Fully Connected Layer (Output Layer)
    Dense(units=10, activation='softmax')
])

# 모델 요약 출력
model.summary()

## 문제 5
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.metrics import CategoricalAccuracy
import numpy as np
import cv2

# 1. 데이터 준비 (MNIST 데이터셋 사용)
mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# 데이터 정규화 및 차원 확장
train_images = train_images.reshape(-1, 32, 32, 1) / 255.0
test_images = test_images.reshape(-1, 32, 32, 1) / 255.0
train_images = tf.image.resize(train_images, [32, 32])
test_images = tf.image.resize(test_images, [32, 32])

# 학습/테스트 데이터 크기 조정
train_cnt = 1000
test_cnt = 200
train_images, train_labels = train_images[:train_cnt], train_labels[:train_cnt]
test_images, test_labels = test_images[:test_cnt], test_labels[:test_cnt]

# 2. LeNet 모델 선언
model = Sequential([
    Input(shape=(32, 32, 1)),  # 32x32 크기의 흑백 이미지
    Conv2D(filters=6, kernel_size=(5, 5), strides=1, activation='tanh', padding='valid'),
    AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'),
    Conv2D(filters=16, kernel_size=(5, 5), strides=1, activation='tanh', padding='valid'),
    AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'),
    Conv2D(filters=120, kernel_size=(5, 5), strides=1, activation='tanh', padding='valid'),
    Flatten(),
    Dense(units=84, activation='tanh'),
    Dense(units=10, activation='softmax')
])

# 3. 모델 컴파일
model.compile(optimizer=Adam(),
              loss=SparseCategoricalCrossentropy(),
              metrics=[CategoricalAccuracy()])

# 4. 모델 학습
model.fit(train_images, train_labels, epochs=1, batch_size=32)

# 5. 모델 평가
loss, accuracy = model.evaluate(test_images, test_labels)
print(f"테스트 데이터 Loss: {loss:.4f}, Accuracy: {accuracy:.4f}")

# 6. 주어진 이미지 예측
# 사용자 업로드 이미지를 32x32로 변환
uploaded_image_path = '/mnt/data/image.png'  # 사용자 업로드 파일 경로
img = cv2.imread(uploaded_image_path, cv2.IMREAD_GRAYSCALE)  # 흑백 이미지 로드
img = cv2.resize(img, (32, 32))  # 32x32로 리사이즈
img = img.reshape(1, 32, 32, 1) / 255.0  # 모델 입력 형태로 변환

# 모델 예측
prediction = model.predict(img)
predicted_class = np.argmax(prediction)
print(f"모델 예측 결과: {predicted_class} (확률: {prediction[0][predicted_class]:.4f})")

## 문제 6
# shuffle=False 학습 결과 저장
results_no_shuffle = model.fit(
    train_images, 
    train_labels, 
    epochs=1, 
    batch_size=32, 
    shuffle=False,  # 데이터 순서를 유지하며 학습
    verbose=1
)

# shuffle=True 학습 결과 저장
results_shuffle = model.fit(
    train_images, 
    train_labels, 
    epochs=1, 
    batch_size=32, 
    shuffle=True,  # 데이터를 무작위로 섞어 학습
    verbose=1
)

# 테스트 데이터 평가
loss_no_shuffle, acc_no_shuffle = model.evaluate(test_images, test_labels, verbose=0)
loss_shuffle, acc_shuffle = model.evaluate(test_images, test_labels, verbose=0)

# 결과 출력
print(f"Shuffle=False: Loss={loss_no_shuffle:.4f}, Accuracy={acc_no_shuffle:.4f}")
print(f"Shuffle=True: Loss={loss_shuffle:.4f}, Accuracy={acc_shuffle:.4f}")

